{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9750039,"sourceType":"datasetVersion","datasetId":5969230}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Imported Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport matplotlib.patches as mpatches\nimport time\n\n# Classifier Libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport collections\n\n\n# Other Libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom collections import Counter\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndf = pd.read_csv('/kaggle/input/loan-approval-classification-data/loan_data.csv')\ndf.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-09T11:29:43.680825Z","iopub.execute_input":"2025-01-09T11:29:43.681037Z","iopub.status.idle":"2025-01-09T11:29:52.666424Z","shell.execute_reply.started":"2025-01-09T11:29:43.681017Z","shell.execute_reply":"2025-01-09T11:29:52.665284Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"   person_age person_gender person_education  person_income  person_emp_exp  \\\n0        22.0        female           Master        71948.0               0   \n1        21.0        female      High School        12282.0               0   \n2        25.0        female      High School        12438.0               3   \n3        23.0        female         Bachelor        79753.0               0   \n4        24.0          male           Master        66135.0               1   \n\n  person_home_ownership  loan_amnt loan_intent  loan_int_rate  \\\n0                  RENT    35000.0    PERSONAL          16.02   \n1                   OWN     1000.0   EDUCATION          11.14   \n2              MORTGAGE     5500.0     MEDICAL          12.87   \n3                  RENT    35000.0     MEDICAL          15.23   \n4                  RENT    35000.0     MEDICAL          14.27   \n\n   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n0                 0.49                         3.0           561   \n1                 0.08                         2.0           504   \n2                 0.44                         3.0           635   \n3                 0.44                         2.0           675   \n4                 0.53                         4.0           586   \n\n  previous_loan_defaults_on_file  loan_status  \n0                             No            1  \n1                            Yes            0  \n2                             No            1  \n3                             No            1  \n4                             No            1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>person_age</th>\n      <th>person_gender</th>\n      <th>person_education</th>\n      <th>person_income</th>\n      <th>person_emp_exp</th>\n      <th>person_home_ownership</th>\n      <th>loan_amnt</th>\n      <th>loan_intent</th>\n      <th>loan_int_rate</th>\n      <th>loan_percent_income</th>\n      <th>cb_person_cred_hist_length</th>\n      <th>credit_score</th>\n      <th>previous_loan_defaults_on_file</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>female</td>\n      <td>Master</td>\n      <td>71948.0</td>\n      <td>0</td>\n      <td>RENT</td>\n      <td>35000.0</td>\n      <td>PERSONAL</td>\n      <td>16.02</td>\n      <td>0.49</td>\n      <td>3.0</td>\n      <td>561</td>\n      <td>No</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21.0</td>\n      <td>female</td>\n      <td>High School</td>\n      <td>12282.0</td>\n      <td>0</td>\n      <td>OWN</td>\n      <td>1000.0</td>\n      <td>EDUCATION</td>\n      <td>11.14</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>504</td>\n      <td>Yes</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25.0</td>\n      <td>female</td>\n      <td>High School</td>\n      <td>12438.0</td>\n      <td>3</td>\n      <td>MORTGAGE</td>\n      <td>5500.0</td>\n      <td>MEDICAL</td>\n      <td>12.87</td>\n      <td>0.44</td>\n      <td>3.0</td>\n      <td>635</td>\n      <td>No</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23.0</td>\n      <td>female</td>\n      <td>Bachelor</td>\n      <td>79753.0</td>\n      <td>0</td>\n      <td>RENT</td>\n      <td>35000.0</td>\n      <td>MEDICAL</td>\n      <td>15.23</td>\n      <td>0.44</td>\n      <td>2.0</td>\n      <td>675</td>\n      <td>No</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24.0</td>\n      <td>male</td>\n      <td>Master</td>\n      <td>66135.0</td>\n      <td>1</td>\n      <td>RENT</td>\n      <td>35000.0</td>\n      <td>MEDICAL</td>\n      <td>14.27</td>\n      <td>0.53</td>\n      <td>4.0</td>\n      <td>586</td>\n      <td>No</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Dense, Layer\nfrom tensorflow.keras.optimizers import RMSprop\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, classification_report\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Custom Attention Layer\nclass Attention(Layer):\n    def __init__(self):\n        super(Attention, self).__init__()\n\n    def build(self, input_shape):\n        self.W = self.add_weight(shape=(input_shape[-1], 1), initializer='random_normal', trainable=True)\n        self.b = self.add_weight(shape=(input_shape[1],), initializer='zeros', trainable=True)\n        super(Attention, self).build(input_shape)\n\n    def call(self, inputs):\n        # Attention mechanism\n        score = K.dot(inputs, self.W)  # (batch_size, timesteps, features) -> (batch_size, timesteps, 1)\n        score = K.reshape(score, (-1, inputs.shape[1]))  # (batch_size, timesteps)\n        score = K.tanh(score + self.b)  # Apply tanh + bias term\n        score = K.softmax(score)  # Normalize with softmax to get attention weights\n        score = K.reshape(score, (-1, inputs.shape[1]))  # Normalize across timesteps\n\n        context_vector = K.batch_dot(score, inputs, axes=[1, 1])  # Weighted sum of inputs\n        return context_vector\n\n# Load your data (Assuming df is already defined as your dataset)\n# df = pd.read_csv('your_dataset.csv') # Uncomment and modify with your actual dataset\n\n# Preprocess numerical features (standardization)\nnumerical_features = [\n    \"person_age\", \"person_income\", \"person_emp_exp\", \"loan_amnt\",\n    \"loan_int_rate\", \"loan_percent_income\", \"cb_person_cred_hist_length\", \"credit_score\"\n]\n\nscaler = StandardScaler()\ndf[numerical_features] = scaler.fit_transform(df[numerical_features])\n\n# Tokenizing and padding text columns (if applicable)\ntext_columns = [\n    \"person_gender\", \"person_education\", \"person_home_ownership\",\n    \"loan_intent\", \"previous_loan_defaults_on_file\"\n]\n\nX_text_list = []\n\nfor text_column in text_columns:\n    tokenizer = Tokenizer(num_words=10000)\n    tokenizer.fit_on_texts(df[text_column])\n    X_text = tokenizer.texts_to_sequences(df[text_column])\n    X_text = pad_sequences(X_text, padding='post', maxlen=100)  # Adjust maxlen as needed\n    X_text_list.append(X_text)\n\n# Concatenate all the padded text columns\nX_text_combined = np.concatenate(X_text_list, axis=1)\n\n# Concatenate text data with numerical features\nX = np.concatenate([X_text_combined, df[numerical_features].values], axis=1)\ny = df['loan_status'].values  # Replace with your target column (binary classification)\n\n# Stratified KFold Cross-Validation\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Prepare a list to store results for each fold\nresults = []\n\n# Initialize lists to store metrics across folds\naccuracies = []\nf1_scores = []\nprecisions = []\nrecalls = []\n\n# Iterate over the folds\nfor train_index, val_index in kf.split(X, y):\n    # Split data into train and validation sets for this fold\n    X_train_fold, X_val_fold = X[train_index], X[val_index]\n    y_train_fold, y_val_fold = y[train_index], y[val_index]\n\n    # Reshape the data for LSTM input (3D input: [samples, timesteps, features])\n    X_train_fold = np.reshape(X_train_fold, (X_train_fold.shape[0], 1, X_train_fold.shape[1]))\n    X_val_fold = np.reshape(X_val_fold, (X_val_fold.shape[0], 1, X_val_fold.shape[1]))\n\n    # Building the Model\n    model = Sequential()\n\n    # First Bidirectional LSTM layer\n    model.add(Bidirectional(LSTM(32, return_sequences=True), input_shape=(X_train_fold.shape[1], X_train_fold.shape[2])))\n    model.add(Dropout(0.5))  # Dropout layer\n\n    # Add Attention layer\n    model.add(Attention())\n\n    # Dense layer (replacing the second Bidirectional LSTM layer)\n    model.add(Dense(16, activation='relu'))\n\n    # Final output layer with sigmoid activation (binary classification)\n    model.add(Dense(1, activation='sigmoid'))\n\n    # Compile the model\n    model.compile(optimizer=RMSprop(), loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Train the model\n    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=64, validation_data=(X_val_fold, y_val_fold), verbose=0)\n\n    # Evaluate the model on the validation set\n    y_pred_fold = model.predict(X_val_fold)\n    y_pred_fold = (y_pred_fold > 0.5).astype(int)\n\n    # Calculate metrics (accuracy, F1-score, precision, recall)\n    accuracy = accuracy_score(y_val_fold, y_pred_fold)\n    f1 = f1_score(y_val_fold, y_pred_fold)\n    precision = precision_score(y_val_fold, y_pred_fold)\n    recall = recall_score(y_val_fold, y_pred_fold)\n\n    # Store the results for this fold\n    accuracies.append(accuracy)\n    f1_scores.append(f1)\n    precisions.append(precision)\n    recalls.append(recall)\n\n# Calculate the average performance metrics across all folds\navg_accuracy = np.mean(accuracies)\navg_f1 = np.mean(f1_scores)\navg_precision = np.mean(precisions)\navg_recall = np.mean(recalls)\n\nprint(f'Average Accuracy: {avg_accuracy:.4f}')\nprint(f'Average F1-Score: {avg_f1:.4f}')\nprint(f'Average Precision: {avg_precision:.4f}')\nprint(f'Average Recall: {avg_recall:.4f}')\n\n# Final evaluation on the test set (optional)\nX_final = np.reshape(X, (X.shape[0], 1, X.shape[1]))  # Reshape X for final evaluation\ny_final = y  # Use the entire dataset as the final evaluation set\n\ny_pred = model.predict(X_final)\ny_pred = (y_pred > 0.5).astype(int)\n\n# Confusion Matrix\ncm = confusion_matrix(y_final, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\n# Classification Report\nprint(\"\\nClassification Report:\\n\", classification_report(y_final, y_pred))\n\n# ROC Curve\nfpr, tpr, _ = roc_curve(y_final, y_pred)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Optionally, show model summary\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Dense, Layer\nfrom tensorflow.keras.optimizers import RMSprop\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve, auc, classification_report\nimport matplotlib.pyplot as plt\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Custom Attention Layer\nclass Attention(Layer):\n    def __init__(self):\n        super(Attention, self).__init__()\n\n    def build(self, input_shape):\n        self.W = self.add_weight(shape=(input_shape[-1], 1), initializer='random_normal', trainable=True)\n        self.b = self.add_weight(shape=(input_shape[1],), initializer='zeros', trainable=True)\n        super(Attention, self).build(input_shape)\n\n    def call(self, inputs):\n        # Attention mechanism\n        score = K.dot(inputs, self.W)  # (batch_size, timesteps, features) -> (batch_size, timesteps, 1)\n        score = K.reshape(score, (-1, inputs.shape[1]))  # (batch_size, timesteps)\n        score = K.tanh(score + self.b)  # Apply tanh + bias term\n        score = K.softmax(score)  # Normalize with softmax to get attention weights\n        score = K.reshape(score, (-1, inputs.shape[1]))  # Normalize across timesteps\n\n        context_vector = K.batch_dot(score, inputs, axes=[1, 1])  # Weighted sum of inputs\n        return context_vector\n\n# Load your data (Assuming df is already defined as your dataset)\n# df = pd.read_csv('your_dataset.csv') # Uncomment and modify with your actual dataset\n\n# Preprocess numerical features (standardization)\nnumerical_features = [\n    \"person_age\", \"person_income\", \"person_emp_exp\", \"loan_amnt\",\n    \"loan_int_rate\", \"loan_percent_income\", \"cb_person_cred_hist_length\", \"credit_score\"\n]\n\nscaler = StandardScaler()\ndf[numerical_features] = scaler.fit_transform(df[numerical_features])\n\n# Tokenizing and padding text columns (if applicable)\ntext_columns = [\n    \"person_gender\", \"person_education\", \"person_home_ownership\",\n    \"loan_intent\", \"previous_loan_defaults_on_file\"\n]\n\nX_text_list = []\n\nfor text_column in text_columns:\n    tokenizer = Tokenizer(num_words=10000)\n    tokenizer.fit_on_texts(df[text_column])\n    X_text = tokenizer.texts_to_sequences(df[text_column])\n    X_text = pad_sequences(X_text, padding='post', maxlen=100)  # Adjust maxlen as needed\n    X_text_list.append(X_text)\n\n# Concatenate all the padded text columns\nX_text_combined = np.concatenate(X_text_list, axis=1)\n\n# Concatenate text data with numerical features\nX = np.concatenate([X_text_combined, df[numerical_features].values], axis=1)\ny = df['loan_status'].values  # Replace with your target column (binary classification)\n\n# Stratified KFold Cross-Validation\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Prepare a list to store results for each fold\nresults = []\n\n# Iterate over the folds\nfor train_index, val_index in kf.split(X, y):\n    # Split data into train and validation sets for this fold\n    X_train_fold, X_val_fold = X[train_index], X[val_index]\n    y_train_fold, y_val_fold = y[train_index], y[val_index]\n\n    # Reshape the data for LSTM input (3D input: [samples, timesteps, features])\n    X_train_fold = np.reshape(X_train_fold, (X_train_fold.shape[0], 1, X_train_fold.shape[1]))\n    X_val_fold = np.reshape(X_val_fold, (X_val_fold.shape[0], 1, X_val_fold.shape[1]))\n\n    # Building the Model\n    model = Sequential()\n\n    # First Bidirectional LSTM layer\n    model.add(Bidirectional(LSTM(32, return_sequences=True), input_shape=(X_train_fold.shape[1], X_train_fold.shape[2])))\n    model.add(Dropout(0.5))  # Dropout layer\n\n    # Add Attention layer\n    model.add(Attention())\n\n    # Dense layer (replacing the second Bidirectional LSTM layer)\n    model.add(Dense(16, activation='relu'))\n\n    # Final output layer with sigmoid activation (binary classification)\n    model.add(Dense(1, activation='sigmoid'))\n\n    # Compile the model\n    model.compile(optimizer=RMSprop(), loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Train the model\n    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=64, validation_data=(X_val_fold, y_val_fold), verbose=0)\n\n    # Evaluate the model on the validation set\n    y_pred_fold = model.predict(X_val_fold)\n    y_pred_fold = (y_pred_fold > 0.5).astype(int)\n\n    # Calculate metrics (accuracy, F1-score)\n    accuracy = accuracy_score(y_val_fold, y_pred_fold)\n    f1 = f1_score(y_val_fold, y_pred_fold)\n\n    # Store the results\n    results.append({'accuracy': accuracy, 'f1': f1})\n\n# Calculate the average performance metrics across all folds\navg_accuracy = np.mean([result['accuracy'] for result in results])\navg_f1 = np.mean([result['f1'] for result in results])\n\nprint(f'Average Accuracy: {avg_accuracy:.4f}')\nprint(f'Average F1-Score: {avg_f1:.4f}')\n\n# Optionally, you can visualize results of confusion matrix or ROC curve on any fold or average\n# Final evaluation of the model (on the last fold, for instance)\ny_pred = model.predict(X_val_fold)\ny_pred = (y_pred > 0.5).astype(int)\n\n# Confusion Matrix\ncm = confusion_matrix(y_val_fold, y_pred)\nprint(\"Confusion Matrix:\\n\", cm)\n\n# Classification Report\nprint(\"\\nClassification Report:\\n\", classification_report(y_val_fold, y_pred))\n\n# ROC Curve\nfpr, tpr, _ = roc_curve(y_val_fold, y_pred)\nroc_auc = auc(fpr, tpr)\n\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Optionally, show model summary\nmodel.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred1 = model.predict(X_train)\ny_pred1 = (y_pred1 > 0.5).astype(int)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(y_train, y_pred1)\nprint(\"Confusion Matrix:\\n\", cm)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classification Report\nprint(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred1))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(df.isnull().sum().max())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.columns)\nprint(df.shape[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T11:30:39.384349Z","iopub.execute_input":"2025-01-09T11:30:39.384651Z","iopub.status.idle":"2025-01-09T11:30:39.390633Z","shell.execute_reply.started":"2025-01-09T11:30:39.384629Z","shell.execute_reply":"2025-01-09T11:30:39.389750Z"}},"outputs":[{"name":"stdout","text":"Index(['person_age', 'person_gender', 'person_education', 'person_income',\n       'person_emp_exp', 'person_home_ownership', 'loan_amnt', 'loan_intent',\n       'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n       'credit_score', 'previous_loan_defaults_on_file', 'loan_status'],\n      dtype='object')\n45000\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# The classes are heavily skewed we need to solve this issue later.\nprint('Approved', round(df['loan_status'].value_counts()[1]/len(df) * 100,2), '% of the dataset')\nprint('Rejected', round(df['loan_status'].value_counts()[0]/len(df) * 100,2), '% of the dataset')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"colors = [\"#0101DF\", \"#DF0101\"]\n\nsns.countplot(x='loan_status', data=df, palette=colors)\nplt.title('Class Distributions \\n (0: Rejetced || 1: Approved)', fontsize=14)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import RobustScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\n\n\n# Define numerical and categorical columns\nnumerical_cols = [\n    \"person_age\", \"person_income\", \"person_emp_exp\", \"loan_amnt\",\n    \"loan_int_rate\", \"loan_percent_income\", \"cb_person_cred_hist_length\", \"credit_score\"\n]\ncategorical_cols = [\n    \"person_gender\", \"person_education\", \"person_home_ownership\",\n    \"loan_intent\", \"previous_loan_defaults_on_file\"\n]\n\n# Scaling numerical features\nscaler = RobustScaler()\n\n# One-hot encoding categorical features\nencoder = OneHotEncoder(drop='first', sparse=False)\n\n# Combine transformations\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", scaler, numerical_cols),\n        (\"cat\", encoder, categorical_cols)\n    ]\n)\n\n# Apply transformations\npreprocessed_data = preprocessor.fit_transform(df)\n\n# Get feature names for the categorical columns\nencoded_columns = preprocessor.named_transformers_[\"cat\"].get_feature_names_out(categorical_cols)\n\n# Combine scaled and encoded features into a DataFrame\nnew_df = pd.DataFrame(\n    preprocessed_data,\n    columns=numerical_cols + list(encoded_columns)\n)\n\n# Include the target variable\nnew_df[\"loan_status\"] = df[\"loan_status\"].values\n\nnew_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T11:30:50.416288Z","iopub.execute_input":"2025-01-09T11:30:50.416614Z","iopub.status.idle":"2025-01-09T11:30:50.548649Z","shell.execute_reply.started":"2025-01-09T11:30:50.416588Z","shell.execute_reply":"2025-01-09T11:30:50.547755Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   person_age  person_income  person_emp_exp  loan_amnt  loan_int_rate  \\\n0   -0.666667       0.100854       -0.571429   3.730699       1.138636   \n1   -0.833333      -1.127215       -0.571429  -0.967218       0.029545   \n2   -0.166667      -1.124004       -0.142857  -0.345435       0.422727   \n3   -0.500000       0.261499       -0.571429   3.730699       0.959091   \n4   -0.333333      -0.018792       -0.428571   3.730699       0.740909   \n\n   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n0             3.083333                        -0.2     -1.144928   \n1            -0.333333                        -0.4     -1.971014   \n2             2.666667                        -0.2     -0.072464   \n3             2.666667                        -0.4      0.507246   \n4             3.416667                         0.0     -0.782609   \n\n   person_gender_male  person_education_Bachelor  ...  \\\n0                 0.0                        0.0  ...   \n1                 0.0                        0.0  ...   \n2                 0.0                        0.0  ...   \n3                 0.0                        1.0  ...   \n4                 1.0                        0.0  ...   \n\n   person_home_ownership_OTHER  person_home_ownership_OWN  \\\n0                          0.0                        0.0   \n1                          0.0                        1.0   \n2                          0.0                        0.0   \n3                          0.0                        0.0   \n4                          0.0                        0.0   \n\n   person_home_ownership_RENT  loan_intent_EDUCATION  \\\n0                         1.0                    0.0   \n1                         0.0                    1.0   \n2                         0.0                    0.0   \n3                         1.0                    0.0   \n4                         1.0                    0.0   \n\n   loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n0                          0.0                  0.0                   1.0   \n1                          0.0                  0.0                   0.0   \n2                          0.0                  1.0                   0.0   \n3                          0.0                  1.0                   0.0   \n4                          0.0                  1.0                   0.0   \n\n   loan_intent_VENTURE  previous_loan_defaults_on_file_Yes  loan_status  \n0                  0.0                                 0.0            1  \n1                  0.0                                 1.0            0  \n2                  0.0                                 0.0            1  \n3                  0.0                                 0.0            1  \n4                  0.0                                 0.0            1  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>person_age</th>\n      <th>person_income</th>\n      <th>person_emp_exp</th>\n      <th>loan_amnt</th>\n      <th>loan_int_rate</th>\n      <th>loan_percent_income</th>\n      <th>cb_person_cred_hist_length</th>\n      <th>credit_score</th>\n      <th>person_gender_male</th>\n      <th>person_education_Bachelor</th>\n      <th>...</th>\n      <th>person_home_ownership_OTHER</th>\n      <th>person_home_ownership_OWN</th>\n      <th>person_home_ownership_RENT</th>\n      <th>loan_intent_EDUCATION</th>\n      <th>loan_intent_HOMEIMPROVEMENT</th>\n      <th>loan_intent_MEDICAL</th>\n      <th>loan_intent_PERSONAL</th>\n      <th>loan_intent_VENTURE</th>\n      <th>previous_loan_defaults_on_file_Yes</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.666667</td>\n      <td>0.100854</td>\n      <td>-0.571429</td>\n      <td>3.730699</td>\n      <td>1.138636</td>\n      <td>3.083333</td>\n      <td>-0.2</td>\n      <td>-1.144928</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.833333</td>\n      <td>-1.127215</td>\n      <td>-0.571429</td>\n      <td>-0.967218</td>\n      <td>0.029545</td>\n      <td>-0.333333</td>\n      <td>-0.4</td>\n      <td>-1.971014</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.166667</td>\n      <td>-1.124004</td>\n      <td>-0.142857</td>\n      <td>-0.345435</td>\n      <td>0.422727</td>\n      <td>2.666667</td>\n      <td>-0.2</td>\n      <td>-0.072464</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.500000</td>\n      <td>0.261499</td>\n      <td>-0.571429</td>\n      <td>3.730699</td>\n      <td>0.959091</td>\n      <td>2.666667</td>\n      <td>-0.4</td>\n      <td>0.507246</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.333333</td>\n      <td>-0.018792</td>\n      <td>-0.428571</td>\n      <td>3.730699</td>\n      <td>0.740909</td>\n      <td>3.416667</td>\n      <td>0.0</td>\n      <td>-0.782609</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX = new_df.drop('loan_status', axis=1)  # Drop target column\ny = new_df['loan_status']  # Target column\n\n# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T11:30:53.055254Z","iopub.execute_input":"2025-01-09T11:30:53.055536Z","iopub.status.idle":"2025-01-09T11:30:53.084874Z","shell.execute_reply.started":"2025-01-09T11:30:53.055516Z","shell.execute_reply":"2025-01-09T11:30:53.084200Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\n# Calculate Q1, Q3, and IQR for numerical columns\nQ1 = X_train[numerical_cols].quantile(0.25)\nQ3 = X_train[numerical_cols].quantile(0.75)\nIQR = Q3 - Q1\n\n# Define outlier thresholds\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Filter rows that fall within the thresholds for all numerical columns\nX_cleared = X_train[\n    ~((X_train[numerical_cols] < lower_bound) | (X_train[numerical_cols] > upper_bound)).any(axis=1)\n]\n# Ensure indices are aligned with the original DataFrame\ny_cleared = y_train.loc[X_cleared.index].reset_index(drop=True)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_cleared.isnull().sum().max()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Verify the shapes match\nprint(f\"Shape of X_cleared: {X_cleared.shape}\")\nprint(f\"Shape of y_train_cleared: {y_cleared.shape}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\n\n# Define the categorical columns\ncategorical_cols = [\n    \"person_gender\", \"person_education\", \"person_home_ownership\",\n    \"loan_intent\", \"previous_loan_defaults_on_file\"\n]\n\n# Initialize LabelEncoder\nencoder = LabelEncoder()\n\n# Apply LabelEncoder to each categorical column\nfor col in categorical_cols:\n    df[col] = encoder.fit_transform(df[col])\n\n# Calculate the correlation matrix\ncorrelation_matrix = df.corr()\n\n# Plot the correlation matrix\nplt.figure(figsize=(12, 8))\nsns.heatmap(\n    correlation_matrix,\n    annot=False,       # Disable annotations inside the squares\n    cmap=\"coolwarm\",  # Color map for the heatmap\n    cbar=True         # Display color bar\n)\n\nplt.title(\"Correlation Matrix \", fontsize=16)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df.shape[1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(new_df.isnull().sum().max())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Store best parameters for each model\n# best_params = {}\n\n# # Optimize each model using Optuna\n# study_logistic = optuna.create_study(direction='maximize')\n# study_logistic.optimize(objective_logistic, n_trials=50)\n# best_params['LogisticRegression'] = study_logistic.best_trial.params\n\n# study_rf = optuna.create_study(direction='maximize')\n# study_rf.optimize(objective_rf, n_trials=50)\n# best_params['RandomForest'] = study_rf.best_trial.params\n\n# study_adaboost = optuna.create_study(direction='maximize')\n# study_adaboost.optimize(objective_adaboost, n_trials=50)\n# best_params['AdaBoost'] = study_adaboost.best_trial.params\n\n# study_gb = optuna.create_study(direction='maximize')\n# study_gb.optimize(objective_gb, n_trials=50)\n# best_params['GradientBoosting'] = study_gb.best_trial.params\n\n# study_xgb = optuna.create_study(direction='maximize')\n# study_xgb.optimize(objective_xgb, n_trials=50)\n# best_params['XGBoost'] = study_xgb.best_trial.params\n\n# study_lgb = optuna.create_study(direction='maximize')\n# study_lgb.optimize(objective_lgb, n_trials=50)\n# best_params['LightGBM'] = study_lgb.best_trial.params\n\n# study_catboost = optuna.create_study(direction='maximize')\n# study_catboost.optimize(objective_catboost, n_trials=50)\n# best_params['CatBoost'] = study_catboost.best_trial.params\n\n# # Print the best parameters\n# for model_name, params in best_params.items():\n#     print(f\"Best Parameters for {model_name}: {params}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# with outliers\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nimport lightgbm as lgb\nimport numpy as np\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# Initialize StratifiedKFold for cross-validation\nsss = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n# Best parameters from Bayesian search\nclassifiers = {\n    'LogisticRegression': LogisticRegression(penalty='l1', C=0.2153901105439295, solver='saga'),\n    'RandomForest': RandomForestClassifier(n_estimators=132, max_depth=15, min_samples_split=3),\n    'AdaBoost': AdaBoostClassifier(n_estimators=143, learning_rate=0.9536417586026401),\n    'GradientBoosting': GradientBoostingClassifier(n_estimators=145, learning_rate=0.19587059159994072, max_depth=5),\n    'XGBoost': XGBClassifier(n_estimators=150, learning_rate=0.2236622678900941, max_depth=5),\n    'LightGBM': lgb.LGBMClassifier(n_estimators=134, learning_rate=0.1417403897878078, max_depth=9),\n    'CatBoost': CatBoostClassifier(iterations=149, learning_rate=0.28167281754280704, depth=6, verbose=0)\n}\n\n# Sampling techniques\nsampling_techniques = [\n    ('SMOTE', SMOTE(sampling_strategy='minority')),\n    ('ADASYN', ADASYN(sampling_strategy='minority')),\n    ('TomekLinks', TomekLinks(sampling_strategy='majority')),\n    ('NearMiss', NearMiss(sampling_strategy='majority'))\n]\n\nmodel_results = {}\n\n# Train and evaluate classifiers\nfor model_name, model in classifiers.items():\n    print(f\"Training and Evaluating {model_name}...\")\n\n    # Store results for each sampling technique\n    test_results = []\n\n    # Loop through sampling techniques\n    for sampler_name, sampler in sampling_techniques:\n        print(f\"Applying {sampler_name}...\")\n\n        # Initialize list to hold metrics for each fold\n        fold_results = []\n\n        # Stratified K-Fold Cross-validation\n        for train_index, val_index in sss.split(X_train, y_train):\n            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n\n            # Create pipeline\n            pipeline = imbalanced_make_pipeline(sampler, model)\n\n            # Fit the pipeline on the training fold\n            pipeline.fit(X_train_fold, y_train_fold)\n\n            # Predict on validation fold\n            predictions_val = pipeline.predict(X_val_fold)\n\n            # Compute metrics for the validation fold\n            val_accuracy = pipeline.score(X_val_fold, y_val_fold)\n            val_precision = precision_score(y_val_fold, predictions_val)\n            val_recall = recall_score(y_val_fold, predictions_val)\n            val_f1 = f1_score(y_val_fold, predictions_val)\n            val_auc = roc_auc_score(y_val_fold, pipeline.predict_proba(X_val_fold)[:, 1])\n\n            # Store fold results\n            fold_results.append({\n                'Accuracy': val_accuracy,\n                'Precision': val_precision,\n                'Recall': val_recall,\n                'F1': val_f1,\n                'AUC': val_auc\n            })\n\n        # Calculate average performance metrics across all folds for this sampling technique\n        avg_accuracy = np.mean([result['Accuracy'] for result in fold_results])\n        avg_precision = np.mean([result['Precision'] for result in fold_results])\n        avg_recall = np.mean([result['Recall'] for result in fold_results])\n        avg_f1 = np.mean([result['F1'] for result in fold_results])\n        avg_auc = np.mean([result['AUC'] for result in fold_results])\n\n        # Append results for this sampling technique\n        test_results.append({\n            'Sampling Technique': sampler_name,\n            'Accuracy': avg_accuracy,\n            'Precision': avg_precision,\n            'Recall': avg_recall,\n            'F1': avg_f1,\n            'AUC': avg_auc\n        })\n\n    # Save results for the model\n    model_results[model_name] = pd.DataFrame(test_results)\n\n# Print test set performance metrics\nprint(\"\\n--- Cross-Validation Performance Metrics ---\")\nfor model_name, df in model_results.items():\n    print(f\"\\nResults for {model_name}:\")\n    print(df[['Sampling Technique', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC']].to_string(index=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nimport lightgbm as lgb\nimport numpy as np\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# Initialize StratifiedKFold for cross-validation\nsss = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n# Best parameters from Bayesian search\nclassifiers = {\n    'LogisticRegression': LogisticRegression(penalty='l1', C=0.2153901105439295, solver='saga'),\n    'RandomForest': RandomForestClassifier(n_estimators=132, max_depth=15, min_samples_split=3),\n    'AdaBoost': AdaBoostClassifier(n_estimators=143, learning_rate=0.9536417586026401),\n    'GradientBoosting': GradientBoostingClassifier(n_estimators=145, learning_rate=0.19587059159994072, max_depth=5),\n    'XGBoost': XGBClassifier(n_estimators=150, learning_rate=0.2236622678900941, max_depth=5),\n    'LightGBM': lgb.LGBMClassifier(n_estimators=134, learning_rate=0.1417403897878078, max_depth=9),\n    'CatBoost': CatBoostClassifier(iterations=149, learning_rate=0.28167281754280704, depth=6, verbose=0)\n}\n\n# Sampling techniques\nsampling_techniques = [\n    ('SMOTE', SMOTE(sampling_strategy='minority')),\n    ('ADASYN', ADASYN(sampling_strategy='minority')),\n    ('TomekLinks', TomekLinks(sampling_strategy='majority')),\n    ('NearMiss', NearMiss(sampling_strategy='majority'))\n]\n\nmodel_results = {}\n\n# Train and evaluate classifiers\nfor model_name, model in classifiers.items():\n    print(f\"Training and Evaluating {model_name}...\")\n\n    # Store results for each sampling technique\n    test_results = []\n\n    # Loop through sampling techniques\n    for sampler_name, sampler in sampling_techniques:\n        print(f\"Applying {sampler_name}...\")\n\n        # Initialize list to hold metrics for each fold\n        fold_results = []\n\n        # Stratified K-Fold Cross-validation\n        for train_index, val_index in sss.split(X, y):\n            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n            y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n\n            # Create pipeline\n            pipeline = imbalanced_make_pipeline(sampler, model)\n\n            # Fit the pipeline on the training fold\n            pipeline.fit(X_train_fold, y_train_fold)\n\n            # Predict on validation fold\n            predictions_val = pipeline.predict(X_val_fold)\n\n            # Compute metrics for the validation fold\n            val_accuracy = pipeline.score(X_val_fold, y_val_fold)\n            val_precision = precision_score(y_val_fold, predictions_val)\n            val_recall = recall_score(y_val_fold, predictions_val)\n            val_f1 = f1_score(y_val_fold, predictions_val)\n            val_auc = roc_auc_score(y_val_fold, pipeline.predict_proba(X_val_fold)[:, 1])\n\n            # Store fold results\n            fold_results.append({\n                'Accuracy': val_accuracy,\n                'Precision': val_precision,\n                'Recall': val_recall,\n                'F1': val_f1,\n                'AUC': val_auc\n            })\n\n        # Calculate average performance metrics across all folds for this sampling technique\n        avg_accuracy = np.mean([result['Accuracy'] for result in fold_results])\n        avg_precision = np.mean([result['Precision'] for result in fold_results])\n        avg_recall = np.mean([result['Recall'] for result in fold_results])\n        avg_f1 = np.mean([result['F1'] for result in fold_results])\n        avg_auc = np.mean([result['AUC'] for result in fold_results])\n\n        # Append results for this sampling technique\n        test_results.append({\n            'Sampling Technique': sampler_name,\n            'Accuracy': avg_accuracy,\n            'Precision': avg_precision,\n            'Recall': avg_recall,\n            'F1': avg_f1,\n            'AUC': avg_auc\n        })\n\n    # Save results for the model\n    model_results[model_name] = pd.DataFrame(test_results)\n\n# Print test set performance metrics\nprint(\"\\n--- Cross-Validation Performance Metrics ---\")\nfor model_name, df in model_results.items():\n    print(f\"\\nResults for {model_name}:\")\n    print(df[['Sampling Technique', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC']].to_string(index=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nimport lightgbm as lgb\nimport numpy as np\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# Initialize StratifiedKFold for cross-validation\nsss = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n# Best parameters from Bayesian search\nclassifiers = {\n    'LogisticRegression': LogisticRegression(penalty='l1', C=0.2153901105439295, solver='saga'),\n    'RandomForest': RandomForestClassifier(n_estimators=132, max_depth=15, min_samples_split=3),\n    'AdaBoost': AdaBoostClassifier(n_estimators=143, learning_rate=0.9536417586026401),\n    'GradientBoosting': GradientBoostingClassifier(n_estimators=145, learning_rate=0.19587059159994072, max_depth=5),\n    'XGBoost': XGBClassifier(n_estimators=150, learning_rate=0.2236622678900941, max_depth=5),\n    'LightGBM': lgb.LGBMClassifier(n_estimators=134, learning_rate=0.1417403897878078, max_depth=9),\n    'CatBoost': CatBoostClassifier(iterations=149, learning_rate=0.28167281754280704, depth=6, verbose=0)\n}\n\n# Sampling techniques\nsampling_techniques = [\n    ('SMOTE', SMOTE(sampling_strategy='minority')),\n    ('ADASYN', ADASYN(sampling_strategy='minority')),\n    ('TomekLinks', TomekLinks(sampling_strategy='majority')),\n    ('NearMiss', NearMiss(sampling_strategy='majority'))\n   \n]\n\nmodel_results = {}\n\n# Train and evaluate classifiers\nfor model_name, model in classifiers.items():\n    print(f\"Training and Evaluating {model_name}...\")\n\n    # Store results for test set\n    test_results = []\n\n    # Loop through sampling techniques\n    for sampler_name, sampler in sampling_techniques:\n        print(f\"Applying {sampler_name}...\")\n\n        # Create pipeline\n        pipeline = imbalanced_make_pipeline(sampler, model)\n        pipeline.fit(X_train, y_train)\n\n        # Predict on test set\n        predictions_test = pipeline.predict(X_test)\n\n        # Compute metrics for the test set\n        test_accuracy = pipeline.score(X_test, y_test)\n        test_precision = precision_score(y_test, predictions_test)\n        test_recall = recall_score(y_test, predictions_test)\n        test_f1 = f1_score(y_test, predictions_test)\n        test_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n\n        # Append results for test set\n        test_results.append({\n            'Sampling Technique': sampler_name,\n            'Accuracy': test_accuracy,\n            'Precision': test_precision,\n            'Recall': test_recall,\n            'F1': test_f1,\n            'AUC': test_auc\n        })\n\n    # Save results for each classifier\n    model_results[model_name] = pd.DataFrame(test_results)\n\n# Print test set performance metrics\nprint(\"\\n--- Test Set Performance Metrics ---\")\nfor model_name, df in model_results.items():\n    print(f\"\\nResults for {model_name}:\")\n    print(df[['Sampling Technique', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC']].to_string(index=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# without outliers","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nimport lightgbm as lgb\nimport numpy as np\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# Classifiers with best parameters (from Bayesian search)\nclassifiers = {\n    'LogisticRegression': LogisticRegression(penalty='l1', C=0.2153901105439295, solver='saga'),\n    'RandomForest': RandomForestClassifier(n_estimators=132, max_depth=15, min_samples_split=3),\n    'AdaBoost': AdaBoostClassifier(n_estimators=143, learning_rate=0.9536417586026401),\n    'GradientBoosting': GradientBoostingClassifier(n_estimators=145, learning_rate=0.19587059159994072, max_depth=5),\n    'XGBoost': XGBClassifier(n_estimators=150, learning_rate=0.2236622678900941, max_depth=5),\n    'LightGBM': lgb.LGBMClassifier(n_estimators=134, learning_rate=0.1417403897878078, max_depth=9),\n    'CatBoost': CatBoostClassifier(iterations=149, learning_rate=0.28167281754280704, depth=6, verbose=0)\n}\n\n# Sampling techniques\nsampling_techniques = [\n    ('SMOTE', SMOTE(sampling_strategy='minority')),\n    ('ADASYN', ADASYN(sampling_strategy='minority')),\n    ('TomekLinks', TomekLinks(sampling_strategy='majority')),\n    ('NearMiss', NearMiss(sampling_strategy='majority')),\n    ('SMOTEENN', SMOTEENN(sampling_strategy='auto'))\n]\n\n# Initialize a dictionary to store results for each model\nmodel_results = {}\n\n# Train and evaluate classifiers\nfor model_name, model in classifiers.items():\n    print(f\"Training and Evaluating {model_name}...\")\n\n    # Store results for the model\n    test_results = []\n\n    # Loop through sampling techniques\n    for sampler_name, sampler in sampling_techniques:\n        print(f\"Applying {sampler_name}...\")\n\n        # Create the pipeline combining the sampling technique and the classifier\n        pipeline = imbalanced_make_pipeline(sampler, model)\n\n        # Fit the pipeline on the entire dataset\n        pipeline.fit(X_cleared, y_cleared)  # Assuming X_cleared and y_cleared are your training data\n\n        # Predict on the test set\n        predictions_test = pipeline.predict(X_test)  # Assuming X_test is your test data\n\n        # Compute metrics for the test set\n        test_accuracy = pipeline.score(X_test, y_test)  # Assuming y_test is your test labels\n        test_precision = precision_score(y_test, predictions_test)\n        test_recall = recall_score(y_test, predictions_test)\n        test_f1 = f1_score(y_test, predictions_test)\n        test_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n\n        # Store the results for the test set\n        test_results.append({\n            'Sampling Technique': sampler_name,\n            'Accuracy': test_accuracy,\n            'Precision': test_precision,\n            'Recall': test_recall,\n            'F1': test_f1,\n            'AUC': test_auc\n        })\n\n    # Store the results for the model\n    model_results[model_name] = pd.DataFrame(test_results)\n\n# Print test set performance metrics\nprint(\"\\n--- Test Set Performance Metrics ---\")\nfor model_name, df in model_results.items():\n    print(f\"\\nResults for {model_name}:\")\n    print(df[['Sampling Technique', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC']].to_string(index=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# finding best parameters with random search\n\n\n","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from imblearn.over_sampling import SMOTE\n# from imblearn.under_sampling import NearMiss\n# from imblearn.combine import SMOTEENN\n# from imblearn.under_sampling import TomekLinks\n# from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n# from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n# from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n# from xgboost import XGBClassifier\n# from catboost import CatBoostClassifier\n# from sklearn.linear_model import LogisticRegression\n# import lightgbm as lgb\n# import numpy as np\n# import warnings\n\n# warnings.filterwarnings(\"ignore\")  \n\n# # Define parameters for RandomizedSearchCV for each model\n# log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n# rf_params = {'n_estimators': [50, 100, 150], 'max_depth': [5, 10, 15], 'min_samples_split': [2, 5, 10]}\n# adaboost_params = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 1]}\n# gb_params = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.5], 'max_depth': [3, 5, 7]}\n# xgb_params = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.3], 'max_depth': [3, 5, 7]}\n# catboost_params = {'iterations': [50, 100, 150], 'depth': [5, 7, 10], 'learning_rate': [0.01, 0.1, 0.3]}\n# lgb_params = {'n_estimators': [50, 100, 150], 'learning_rate': [0.01, 0.1, 0.3], 'max_depth': [5, 7, 10]}\n\n# # Initialize StratifiedKFold for cross-validation\n# sss = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n# # Sampling techniques\n# sampling_techniques = [\n#     ('SMOTE', SMOTE(sampling_strategy='minority')),\n#     ('TomekLinks', TomekLinks(sampling_strategy='majority')),\n#     ('NearMiss', NearMiss(sampling_strategy='majority')),\n#     ('SMOTEENN', SMOTEENN(sampling_strategy='auto'))\n# ]\n\n# # --- Perform Random Search to Determine Best Parameters ---\n\n# # List of classifiers\n# classifiers = {\n#     'LogisticRegression': LogisticRegression(),\n#     'RandomForest': RandomForestClassifier(),\n#     'AdaBoost': AdaBoostClassifier(),\n#     'GradientBoosting': GradientBoostingClassifier(),\n#     'XGBoost': XGBClassifier(),\n#     'LightGBM': lgb.LGBMClassifier(),\n#     'CatBoost': CatBoostClassifier(verbose=0)\n# }\n\n# # Parameter grids for each model\n# param_grids = {\n#     'LogisticRegression': log_reg_params,\n#     'RandomForest': rf_params,\n#     'AdaBoost': adaboost_params,\n#     'GradientBoosting': gb_params,\n#     'XGBoost': xgb_params,\n#     'LightGBM': lgb_params,\n#     'CatBoost': catboost_params\n# }\n\n# best_params = {}\n\n# for model_name, model in classifiers.items():\n#     print(f\"Performing Random Search for {model_name}...\")\n#     rand_search = RandomizedSearchCV(model, param_grids[model_name], n_iter=4, random_state=42, cv=3)\n#     rand_search.fit(X_train, y_train)\n#     best_params[model_name] = rand_search.best_params_\n#     print(f\"Best Parameters for {model_name}: {best_params[model_name]}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# model trained using random search params","metadata":{}},{"cell_type":"code","source":"# import pandas as pd\n# from imblearn.over_sampling import SMOTE\n# from imblearn.under_sampling import NearMiss\n# from imblearn.combine import SMOTEENN\n# from imblearn.under_sampling import TomekLinks\n# from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n# from sklearn.model_selection import StratifiedKFold\n# from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score\n# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n# from xgboost import XGBClassifier\n# from catboost import CatBoostClassifier\n# from sklearn.linear_model import LogisticRegression\n# import lightgbm as lgb\n# import numpy as np\n# import matplotlib.pyplot as plt\n# import warnings\n\n# warnings.filterwarnings(\"ignore\")\n\n# # Initialize StratifiedKFold for cross-validation\n# sss = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n\n\n\n# classifiers = {\n#     'LogisticRegression': LogisticRegression(penalty='l2', C=10),\n#     'RandomForest': RandomForestClassifier(n_estimators=50, max_depth=15, min_samples_split=5),\n#     'AdaBoost': AdaBoostClassifier(n_estimators=100, learning_rate=1),\n#     'GradientBoosting': GradientBoostingClassifier(n_estimators=50, max_depth=5, learning_rate=0.5),\n#     'XGBoost': XGBClassifier(n_estimators=50, max_depth=5, learning_rate=0.3),\n#     'LightGBM': lgb.LGBMClassifier(n_estimators=100, max_depth=7, learning_rate=0.1),\n#     'CatBoost': CatBoostClassifier(iterations=150, depth=5, learning_rate=0.3, verbose=0)\n# }\n\n\n# # Sampling techniques\n# sampling_techniques = [\n#     ('SMOTE', SMOTE(sampling_strategy='minority')),\n#     ('ADASYN', ADASYN(sampling_strategy='minority')),\n#     ('TomekLinks', TomekLinks(sampling_strategy='majority')),\n#     ('NearMiss', NearMiss(sampling_strategy='majority')),\n#     ('SMOTEENN', SMOTEENN(sampling_strategy='auto'))\n# ]\n\n# model_results = {}\n\n# # Train and evaluate classifiers\n# for model_name, model in classifiers.items():\n#     print(f\"Training and Evaluating {model_name}...\")\n\n#     # Store results for test set\n#     test_results = []\n\n#     # Loop through sampling techniques\n#     for sampler_name, sampler in sampling_techniques:\n#         print(f\"Applying {sampler_name}...\")\n\n#         # Create pipeline\n#         pipeline = imbalanced_make_pipeline(sampler, model)\n#         pipeline.fit(X_cleared, y_cleared)\n\n#         # Predict on test set\n#         predictions_test = pipeline.predict(X_test)\n\n#         # Compute metrics for the test set\n#         test_accuracy = pipeline.score(X_test, y_test)\n#         test_precision = precision_score(y_test, predictions_test)\n#         test_recall = recall_score(y_test, predictions_test)\n#         test_f1 = f1_score(y_test, predictions_test)\n#         test_auc = roc_auc_score(y_test, pipeline.predict_proba(X_test)[:, 1])\n\n#         # Append results for test set\n#         test_results.append({\n#             'Sampling Technique': sampler_name,\n#             'Accuracy': test_accuracy,\n#             'Precision': test_precision,\n#             'Recall': test_recall,\n#             'F1': test_f1,\n#             'AUC': test_auc\n#         })\n\n#     # Save results for each classifier\n#     model_results[model_name] = pd.DataFrame(test_results)\n\n# # Print test set performance metrics\n# print(\"\\n--- Test Set Performance Metrics ---\")\n# for model_name, df in model_results.items():\n#     print(f\"\\nResults for {model_name}:\")\n#     print(df[['Sampling Technique', 'Accuracy', 'Precision', 'Recall', 'F1', 'AUC']].to_string(index=False))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# voting classifier","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom imblearn.over_sampling import ADASYN\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, make_scorer\nfrom sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport lightgbm as lgb\nimport numpy as np\n\n# Initialize classifiers\ngb = GradientBoostingClassifier(n_estimators=145, learning_rate=0.19587059159994072, max_depth=5)\nXGB = XGBClassifier(n_estimators=150, learning_rate=0.2236622678900941, max_depth=5)\nLGB = lgb.LGBMClassifier(n_estimators=134, learning_rate=0.1417403897878078, max_depth=9)\nCat = CatBoostClassifier(iterations=149, learning_rate=0.28167281754280704, depth=6, verbose=0)\n\n# Sampling technique\ntomek = TomekLinks()\n\n# Clean data using TomekLinks\nX_train_cleaned, y_train_cleaned = tomek.fit_resample(X, y)\n\n# Voting Classifier setup\nvoting_clf = VotingClassifier(\n    estimators=[\n        ('GradientBoosting', gb),\n        ('XGBoost', XGB),\n        ('LightGBM', LGB),\n        ('CatBoost', Cat)\n    ],\n    voting='soft'\n)\n\n# Define 5-fold cross-validation\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Scoring metrics for cross-validation\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'f1': make_scorer(f1_score),\n    'roc_auc': make_scorer(roc_auc_score, needs_proba=True)\n}\n\n# Perform 5-fold cross-validation\nprint(\"Performing 5-Fold Cross-Validation on Voting Classifier...\")\n\nresults = {}\nfor metric in scoring:\n    scores = cross_val_score(voting_clf, X_train_cleaned, y_train_cleaned, cv=cv, scoring=scoring[metric], n_jobs=-1)\n    results[metric] = scores\n\n# Print mean scores\nprint(\"\\n--- 5-Fold Cross-Validation Results ---\")\nfor metric, scores in results.items():\n    print(f\"{metric.capitalize()}: Mean = {np.mean(scores):.4f}, Std = {np.std(scores):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T11:56:30.239025Z","iopub.execute_input":"2025-01-09T11:56:30.239373Z","iopub.status.idle":"2025-01-09T11:59:53.276690Z","shell.execute_reply.started":"2025-01-09T11:56:30.239344Z","shell.execute_reply":"2025-01-09T11:59:53.275580Z"}},"outputs":[{"name":"stdout","text":"Performing 5-Fold Cross-Validation on Voting Classifier...\n\n--- 5-Fold Cross-Validation Results ---\nAccuracy: Mean = 0.9397, Std = 0.0038\nPrecision: Mean = 0.9027, Std = 0.0122\nRecall: Mean = 0.8256, Std = 0.0114\nF1: Mean = 0.8624, Std = 0.0087\nRoc_auc: Mean = 0.9831, Std = 0.0007\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nfrom imblearn.over_sampling import ADASYN\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, make_scorer\nfrom sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nimport lightgbm as lgb\nimport numpy as np\n\n# Initialize classifiers\ngb = GradientBoostingClassifier(n_estimators=145, learning_rate=0.19587059159994072, max_depth=5)\nXGB = XGBClassifier(n_estimators=150, learning_rate=0.2236622678900941, max_depth=5)\n# LGB = lgb.LGBMClassifier(n_estimators=134, learning_rate=0.1417403897878078, max_depth=9)\n# Cat = CatBoostClassifier(iterations=149, learning_rate=0.28167281754280704, depth=6, verbose=0)\n\n# Sampling technique\ntomek = TomekLinks()\n\n# Clean data using TomekLinks\nX_train_cleaned, y_train_cleaned = tomek.fit_resample(X, y)\n\n# Voting Classifier setup\nvoting_clf = VotingClassifier(\n    estimators=[\n        ('GradientBoosting', gb),\n        ('XGBoost', XGB),\n        ('LightGBM', LGB),\n        ('CatBoost', Cat)\n    ],\n    voting='soft'\n)\n\n# Define 5-fold cross-validation\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Scoring metrics for cross-validation\nscoring = {\n    'accuracy': 'accuracy',\n    'precision': make_scorer(precision_score),\n    'recall': make_scorer(recall_score),\n    'f1': make_scorer(f1_score),\n    'roc_auc': make_scorer(roc_auc_score, needs_proba=True)\n}\n\n# Perform 5-fold cross-validation\nprint(\"Performing 5-Fold Cross-Validation on Voting Classifier...\")\n\nresults = {}\nfor metric in scoring:\n    scores = cross_val_score(voting_clf, X_train_cleaned, y_train_cleaned, cv=cv, scoring=scoring[metric], n_jobs=-1)\n    results[metric] = scores\n\n# Print mean scores\nprint(\"\\n--- 5-Fold Cross-Validation Results ---\")\nfor metric, scores in results.items():\n    print(f\"{metric.capitalize()}: Mean = {np.mean(scores):.4f}, Std = {np.std(scores):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T11:52:52.667577Z","iopub.execute_input":"2025-01-09T11:52:52.668038Z","iopub.status.idle":"2025-01-09T11:56:18.079538Z","shell.execute_reply.started":"2025-01-09T11:52:52.668001Z","shell.execute_reply":"2025-01-09T11:56:18.078464Z"}},"outputs":[{"name":"stdout","text":"Performing 5-Fold Cross-Validation on Voting Classifier...\n\n--- 5-Fold Cross-Validation Results ---\nAccuracy: Mean = 0.9398, Std = 0.0038\nPrecision: Mean = 0.9027, Std = 0.0121\nRecall: Mean = 0.8257, Std = 0.0114\nF1: Mean = 0.8623, Std = 0.0087\nRoc_auc: Mean = 0.9831, Std = 0.0007\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Stacking Classifier","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nfrom sklearn.ensemble import GradientBoostingClassifier, StackingClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import SMOTE  # Import SMOTE for oversampling\n\n# Initialize classifiers with specified hyperparameters\ngb = GradientBoostingClassifier(n_estimators=145, learning_rate=0.19587059159994072, max_depth=5, random_state=42)\nxgb = XGBClassifier(n_estimators=150, learning_rate=0.2236622678900941, max_depth=5, use_label_encoder=False, eval_metric='logloss', random_state=42)\nlgb = lgb.LGBMClassifier(n_estimators=134, learning_rate=0.1417403897878078, max_depth=9, random_state=42)\ncat = CatBoostClassifier(iterations=149, learning_rate=0.28167281754280704, depth=6, verbose=0, random_state=42)\n\n\n# Perform SMOTE Oversampling on the training set\nsmote = SMOTE(random_state=42)  # Initialize SMOTE\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)  \n# Create Stacking Classifier\nstacking_clf = StackingClassifier(\n    estimators=[\n        ('gb', gb),\n        ('xgb', xgb),\n        ('lgb', lgb),\n        ('cat', cat)\n    ],\n    final_estimator=LogisticRegression(),\n    cv=5,  # 5-fold cross-validation\n    n_jobs=-1\n)\n\n# Train Stacking Classifier on the resampled dataset\nstacking_clf.fit(X_train_resampled, y_train_resampled)\n\n# Predict on test set\ny_pred = stacking_clf.predict(X_test)\ny_proba = stacking_clf.predict_proba(X_test)[:, 1]  # Get probability scores for ROC AUC\n\n# Evaluate performance\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, y_proba)\n\n# Print metrics\nprint(\"Stacking Classifier Performance After SMOTE Oversampling:\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")\nprint(f\"ROC AUC: {roc_auc:.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Deep Learning CNN\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, roc_auc_score, classification_report\nfrom sklearn.model_selection import train_test_split\n\n# Assuming you've already loaded your data and split it into X_train, X_test, y_train, and y_test\n\n# Model Architecture\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Define the ReduceLROnPlateau callback\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',    # Monitor validation loss\n    factor=0.5,            # Reduce LR by half when the validation loss plateaus\n    patience=3,            # Number of epochs to wait for improvement\n    min_lr=1e-6,           # Minimum learning rate\n    verbose=1              # Print messages when learning rate changes\n)\n\n# Train the model with the ReduceLROnPlateau callback\nmodel.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[reduce_lr])\n\n# Predict on the test set\ny_pred = (model.predict(X_test) > 0.5).astype(\"int32\")  # Convert probabilities to binary (0 or 1)\ny_proba = model.predict(X_test)  # To get probability scores for ROC AUC\n\n# Calculate performance metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, y_proba)\n\n# Print metrics\nprint(\"Model Performance:\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")\nprint(f\"ROC AUC: {roc_auc:.4f}\")\n\n# Print detailed classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Explainable AI - LIME","metadata":{}},{"cell_type":"code","source":"from imblearn.under_sampling import TomekLinks\nfrom sklearn.pipeline import Pipeline\nfrom lightgbm import LGBMClassifier\nimport shap\nfrom lime.lime_tabular import LimeTabularExplainer\n\n# Apply TomekLinks preprocessing\ntomek = TomekLinks()\nX_train_cleaned, y_train_cleaned = tomek.fit_resample(X_train, y_train)\n\n# Define the pipeline with only the model\nbest_pipeline = Pipeline([\n    ('model', LGBMClassifier(n_estimators=134, learning_rate=0.1417403897878078, max_depth=9))  # Model\n])\n\n# Fit the pipeline on the preprocessed training data\nbest_pipeline.fit(X_train_cleaned, y_train_cleaned)\n\n# Initialize SHAP explainer visualization support\nshap.initjs()\n\nprint(\"\\n--- LIME Explanations on Last Fold ---\")\n\nfrom lime.lime_tabular import LimeTabularExplainer\n\n# Convert training data to NumPy array\nX_train_cleaned_np = X_train_cleaned.to_numpy()\n\n# Initialize LIME Explainer\nlime_explainer = LimeTabularExplainer(\n    training_data=X_train_cleaned_np,\n    feature_names=list(X_train_cleaned.columns),\n    class_names=[\"Rejected\", \"Approved\"],\n    mode=\"classification\"\n)\n\n# Select a sample to explain (first instance in test data)\nsample_idx = 0\nsample = X_test.iloc[sample_idx].values  # Ensure X_test is a DataFrame or adapt accordingly\nprint(f\"Explaining instance {sample_idx} from test set.\")\n\n# Generate explanation\nlime_exp = lime_explainer.explain_instance(\n    data_row=sample,\n    predict_fn=best_pipeline.predict_proba\n)\n\n# Show explanation\nlime_exp.show_in_notebook()  \nprint(lime_exp.as_list())\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# SHAP Summary Plot\n","metadata":{}},{"cell_type":"code","source":"import shap\nimport matplotlib.pyplot as plt\n\n# Initialize SHAP explainer\nshap_explainer = shap.Explainer(best_pipeline.named_steps['model'], X_train_cleaned)\n\n# Calculate SHAP values for the test data with additivity check disabled\nshap_values = shap_explainer(X_test, check_additivity=False)\n\n# Summary plot\nprint(\"\\n--- SHAP Summary Plot ---\")\nshap.summary_plot(shap_values, X_test, plot_type=\"dot\")\n\n# Violin plot\nprint(\"\\n--- SHAP Violin Plot ---\")\nshap.summary_plot(shap_values, X_test, plot_type=\"violin\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}